{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 심사 기준     : **RMSLE(Root Mean Squared Logarithmic Error)** of ECLO  \n",
    "- ECLO         : 인명피해 심각도(Equivalent Casualty Loss Only)  \n",
    "- **ECLO = 사망자수 * 10 + 중상자수 * 5 + 경상자수 * 3 + 부상자수 * 1**\n",
    "- 다른 유형의 사고들을 부상자 기준으로 환산하여 사고의 심각 정도와 위험도를 표현하는 방법  \n",
    "- 부상자       : 교통사고로 인하여 5일 미만의 치료를 요하는 부상을 입은 경우   \n",
    "- Public Score : 전체 테스트 데이터 중 30%  \n",
    "- Private Score: 전체 테스트 데이터 중 70%  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/users/jjong/desktop/vscode/Dacon_src/Daegu/train.csv')\n",
    "test = pd.read_csv('/users/jjong/desktop/vscode/Dacon_src/Daegu/test.csv')\n",
    "sample = pd.read_csv('/users/jjong/desktop/vscode/Dacon_src/Daegu/sample_submission.csv')\n",
    "accident = pd.read_csv('/users/jjong/desktop/vscode/Dacon_src/Daegu/external_open/countrywide_accident.csv')\n",
    "cctv = pd.read_csv('/users/jjong/desktop/vscode/Dacon_src/Daegu/external_open/대구 CCTV 정보.csv', encoding='euc-kr')\n",
    "light = pd.read_csv('/users/jjong/desktop/vscode/Dacon_src/Daegu/external_open/대구 보안등 정보.csv', encoding='euc-kr')\n",
    "kid = pd.read_csv('/users/jjong/desktop/vscode/Dacon_src/Daegu/external_open/대구 어린이 보호 구역 정보.csv', encoding='euc-kr')\n",
    "park = pd.read_csv('/users/jjong/desktop/vscode/Dacon_src/Daegu/external_open/대구 주차장 정보.csv', encoding='euc-kr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rmsle(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Root Mean Squared Logarithmic Error (RMSLE) 계산\n",
    "    \n",
    "    Parameters:\n",
    "    - y_true: 실제 값 배열\n",
    "    - y_pred: 예측 값 배열\n",
    "    \n",
    "    Returns:\n",
    "    - rmsle_score: RMSLE 점수\n",
    "    \"\"\"\n",
    "    assert len(y_true) == len(y_pred), \"입력 배열의 길이가 같아야 합니다.\"\n",
    "    \n",
    "    # 각 값에 1을 더하고 로그 취하기\n",
    "    log_diff = np.log1p(y_pred) - np.log1p(y_true)\n",
    "    \n",
    "    # 제곱하기\n",
    "    squared_log_diff = np.square(log_diff)\n",
    "    \n",
    "    # 평균 구하기\n",
    "    mean_squared_log_diff = np.mean(squared_log_diff)\n",
    "    \n",
    "    # 제곱근 취하기\n",
    "    rmsle_score = np.sqrt(mean_squared_log_diff)\n",
    "    \n",
    "    return rmsle_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/users/jjong/desktop/vscode/Dacon_src/Daegu/train.csv')\n",
    "test = pd.read_csv('/users/jjong/desktop/vscode/Dacon_src/Daegu/test.csv')\n",
    "sample = pd.read_csv('/users/jjong/desktop/vscode/Dacon_src/Daegu/sample_submission.csv')\n",
    "accident = pd.read_csv('/users/jjong/desktop/vscode/Dacon_src/Daegu/external_open/countrywide_accident.csv')\n",
    "cctv = pd.read_csv('/users/jjong/desktop/vscode/Dacon_src/Daegu/external_open/대구 CCTV 정보.csv', encoding='euc-kr')\n",
    "light = pd.read_csv('/users/jjong/desktop/vscode/Dacon_src/Daegu/external_open/대구 보안등 정보.csv', encoding='euc-kr')\n",
    "kid = pd.read_csv('/users/jjong/desktop/vscode/Dacon_src/Daegu/external_open/대구 어린이 보호 구역 정보.csv', encoding='euc-kr')\n",
    "park = pd.read_csv('/users/jjong/desktop/vscode/Dacon_src/Daegu/external_open/대구 주차장 정보.csv', encoding='euc-kr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(['ID', '사고일시', '시군구'], axis=1, inplace=True)\n",
    "test.drop(['ID', '사고일시', '시군구'], axis=1, inplace=True)\n",
    "accident.drop(['ID', '사고일시', '시군구'], axis=1, inplace=True)\n",
    "train = train.dropna()\n",
    "accident = accident.dropna()\n",
    "train = train[train['피해운전자 연령'] != '미분류']\n",
    "train = train[train['가해운전자 연령'] != '미분류']\n",
    "accident = accident[accident['피해운전자 연령'] != '미분류']\n",
    "accident = accident[accident['가해운전자 연령'] != '미분류']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['피해운전자 연령'] = train['피해운전자 연령'].apply(lambda x: '90' if x == '90세 이상' else x)\n",
    "train['피해운전자 연령'] = train['피해운전자 연령'].apply(lambda x: '98' if x == '98세 이상' else x)\n",
    "train['피해운전자 연령'] = train['피해운전자 연령'].apply(lambda x: '98' if x == '98 이상' else x)\n",
    "train['가해운전자 연령'] = train['가해운전자 연령'].apply(lambda x: '90' if x == '90세 이상' else x)\n",
    "train['가해운전자 연령'] = train['가해운전자 연령'].apply(lambda x: '90' if x == '98세 이상' else x)\n",
    "accident['가해운전자 연령'] = accident['가해운전자 연령'].apply(lambda x: '90' if x == '90세 이상' else x)\n",
    "accident['가해운전자 연령'] = accident['가해운전자 연령'].apply(lambda x: '90' if x == '98세 이상' else x)\n",
    "accident['피해운전자 연령'] = accident['피해운전자 연령'].apply(lambda x: '90' if x == '90세 이상' else x)\n",
    "accident['피해운전자 연령'] = accident['피해운전자 연령'].apply(lambda x: '98' if x == '98세 이상' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['피해운전자 연령'] = [i.replace('세', '') for i in train['피해운전자 연령']]\n",
    "train['피해운전자 연령'] = train['피해운전자 연령'].astype(int)\n",
    "\n",
    "train['가해운전자 연령'] = [i.replace('세', '') for i in train['가해운전자 연령']]\n",
    "train['가해운전자 연령'] = train['가해운전자 연령'].astype(int)\n",
    "\n",
    "accident['피해운전자 연령'] = [i.replace('세', '') for i in accident['피해운전자 연령']]\n",
    "accident['피해운전자 연령'] = accident['피해운전자 연령'].astype(int)\n",
    "\n",
    "accident['가해운전자 연령'] = [i.replace('세', '') for i in accident['가해운전자 연령']]\n",
    "accident['가해운전자 연령'] = accident['가해운전자 연령'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['가해운전자 성별'] = train['가해운전자 성별'].apply(lambda x: 0 if x == '남' else 1 if x == '여' else 2)\n",
    "train['피해운전자 성별'] = train['피해운전자 성별'].apply(lambda x: 0 if x == '남' else 1 if x == '여' else 2)\n",
    "accident['피해운전자 성별'] = accident['피해운전자 성별'].apply(lambda x: 0 if x == '남' else 1 if x == '여' else 2)\n",
    "accident['가해운전자 성별'] = accident['가해운전자 성별'].apply(lambda x: 0 if x == '남' else 1 if x == '여' else 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['가해운전자 상해정도'] = train['가해운전자 상해정도'].apply(lambda x: 0 if x == '상해없음' else 1 if x == '부상신고' or x == '기타불명' else 3 if x == '경상' else 5 if x == '중상' else 10)\n",
    "train['피해운전자 상해정도'] = train['피해운전자 상해정도'].apply(lambda x: 0 if x == '상해없음' else 1 if x == '부상신고' or x == '기타불명' else 3 if x == '경상' else 5 if x == '중상' else 10)\n",
    "accident['피해운전자 상해정도'] = accident['피해운전자 상해정도'].apply(lambda x: 0 if x == '상해없음' else 1 if x == '부상신고' or x == '기타불명' else 3 if x == '경상' else 5 if x == '중상' else 10)\n",
    "accident['가해운전자 상해정도'] = accident['가해운전자 상해정도'].apply(lambda x: 0 if x == '상해없음' else 1 if x == '부상신고' or x == '기타불명' else 3 if x == '경상' else 5 if x == '중상' else 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "accident = accident[accident['노면상태'] != '해빙']\n",
    "accident = accident[accident['도로형태'] != '단일로 - 철길건널목']\n",
    "accident = accident[accident['사고유형 - 세부분류'] != '철길건널목']\n",
    "accident = accident[accident['사고유형'] != '철길건널목']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "accident['사고유형'] = accident['사고유형'].apply(lambda x: 0 if x == '차대차' else 1 if '차대사람' else 2)\n",
    "train['사고유형'] = train['사고유형'].apply(lambda x: 0 if x == '차대차' else 1  if'차대사람' else 2)\n",
    "test['사고유형'] = test['사고유형'].apply(lambda x: 0 if x == '차대차' else 1 if '차대사람' else 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "acc_dummy = pd.get_dummies(accident[['기상상태', '도로형태', '사고유형']])\n",
    "train_dummy = pd.get_dummies(train[['기상상태', '도로형태', '사고유형']])\n",
    "test_dummy = pd.get_dummies(test[['기상상태', '도로형태', '사고유형']])\n",
    "\n",
    "y_acc = accident[['사망자수', '중상자수', '경상자수', '부상자수']]\n",
    "y_tra = train[['사망자수', '중상자수', '경상자수', '부상자수']]\n",
    "\n",
    "train_dummy = train_dummy.drop('기상상태_안개', axis=1)\n",
    "acc_dummy = acc_dummy.drop('기상상태_안개', axis=1)\n",
    "\n",
    "# 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_dummy, y_tra, test_size=0.2)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(acc_dummy, y_acc, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "std = StandardScaler()\n",
    "X_train_sc = std.fit_transform(X_train)\n",
    "X_test_sc = std.transform(X_test)\n",
    "test_sc = std.transform(test_dummy)\n",
    "\n",
    "mm = MinMaxScaler()\n",
    "\n",
    "X_train_mm = mm.fit_transform(X_train)\n",
    "X_test_mm = mm.transform(X_test)\n",
    "test_mm = mm.transform(test_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_23 (InputLayer)       [(None, 17)]              0         \n",
      "                                                                 \n",
      " dense_236 (Dense)           (None, 256)               4608      \n",
      "                                                                 \n",
      " batch_normalization_207 (B  (None, 256)               1024      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dropout_155 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_237 (Dense)           (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_208 (B  (None, 128)               512       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dropout_156 (Dropout)       (None, 128)               0         \n",
      "                                                                 \n",
      " dense_238 (Dense)           (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_209 (B  (None, 64)                256       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dropout_157 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_239 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " batch_normalization_210 (B  (None, 32)                128       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dropout_158 (Dropout)       (None, 32)                0         \n",
      "                                                                 \n",
      " dense_240 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " batch_normalization_211 (B  (None, 16)                64        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dropout_159 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_241 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " batch_normalization_212 (B  (None, 8)                 32        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dropout_160 (Dropout)       (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_242 (Dense)           (None, 4)                 36        \n",
      "                                                                 \n",
      " batch_normalization_213 (B  (None, 4)                 16        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dropout_161 (Dropout)       (None, 4)                 0         \n",
      "                                                                 \n",
      " dense_243 (Dense)           (None, 4)                 20        \n",
      "                                                                 \n",
      " batch_normalization_214 (B  (None, 4)                 16        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dropout_162 (Dropout)       (None, 4)                 0         \n",
      "                                                                 \n",
      " dense_244 (Dense)           (None, 8)                 40        \n",
      "                                                                 \n",
      " batch_normalization_215 (B  (None, 8)                 32        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dropout_163 (Dropout)       (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_245 (Dense)           (None, 16)                144       \n",
      "                                                                 \n",
      " batch_normalization_216 (B  (None, 16)                64        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dropout_164 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_246 (Dense)           (None, 32)                544       \n",
      "                                                                 \n",
      " batch_normalization_217 (B  (None, 32)                128       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dropout_165 (Dropout)       (None, 32)                0         \n",
      "                                                                 \n",
      " dense_247 (Dense)           (None, 64)                2112      \n",
      "                                                                 \n",
      " batch_normalization_218 (B  (None, 64)                256       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dropout_166 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_248 (Dense)           (None, 8)                 520       \n",
      "                                                                 \n",
      " batch_normalization_219 (B  (None, 8)                 32        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dropout_167 (Dropout)       (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_249 (Dense)           (None, 4)                 36        \n",
      "                                                                 \n",
      " batch_normalization_220 (B  (None, 4)                 16        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_250 (Dense)           (None, 4)                 20        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 54552 (213.09 KB)\n",
      "Trainable params: 53264 (208.06 KB)\n",
      "Non-trainable params: 1288 (5.03 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# 1. 기본 모델 훈련\n",
    "input_shape = (X_train_sc.shape[1],)\n",
    "output_shape = (4,)\n",
    "\n",
    "# 기본 모델 구성\n",
    "input_layer = Input(shape=input_shape)\n",
    "x = Dense(256, activation='relu')(input_layer)\n",
    "x = BatchNormalization()(x) \n",
    "x = Dropout(0.5)(x)  \n",
    "\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = BatchNormalization()(x) \n",
    "x = Dropout(0.4)(x)  \n",
    "\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = BatchNormalization()(x) \n",
    "x = Dropout(0.4)(x)  \n",
    "\n",
    "x = Dense(32, activation='relu')(x)\n",
    "x = BatchNormalization()(x) \n",
    "x = Dropout(0.4)(x)  \n",
    "\n",
    "x = Dense(16, activation='relu')(x)\n",
    "x = BatchNormalization()(x) \n",
    "x = Dropout(0.4)(x)  \n",
    "\n",
    "x = Dense(8, activation='relu')(x)\n",
    "x = BatchNormalization()(x) \n",
    "x = Dropout(0.4)(x)  \n",
    "\n",
    "x = Dense(4, activation='relu')(x)\n",
    "x = BatchNormalization()(x) \n",
    "x = Dropout(0.4)(x)  \n",
    "\n",
    "x = Dense(4, activation='relu')(x)\n",
    "x = BatchNormalization()(x) \n",
    "x = Dropout(0.4)(x)  \n",
    "\n",
    "x = Dense(8, activation='relu')(x)\n",
    "x = BatchNormalization()(x) \n",
    "x = Dropout(0.4)(x)  \n",
    "\n",
    "x = Dense(16, activation='relu')(x)\n",
    "x = BatchNormalization()(x) \n",
    "x = Dropout(0.4)(x)  \n",
    "\n",
    "x = Dense(32, activation='relu')(x)\n",
    "x = BatchNormalization()(x) \n",
    "x = Dropout(0.4)(x)  \n",
    "\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = BatchNormalization()(x) \n",
    "x = Dropout(0.4)(x)  \n",
    "\n",
    "x = Dense(8, activation='relu')(x)\n",
    "x = BatchNormalization()(x) \n",
    "x = Dropout(0.4)(x)  \n",
    "\n",
    "x = Dense(4, activation='relu')(x)\n",
    "x = BatchNormalization()(x) \n",
    "output_layer = Dense(output_shape[0], activation='linear')(x)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "# 모델 컴파일 및 훈련\n",
    "model.compile(optimizer=optimizer, loss='mean_squared_error', metrics='mse')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# # EarlyStopping 콜백 설정\n",
    "# # early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# # 간소화된 모델 구성\n",
    "# input_layer = Input(shape=input_shape)\n",
    "# x = Dense(64, activation='relu')(input_layer)\n",
    "# x = BatchNormalization()(x) \n",
    "# x = Dense(32, activation='relu')(x)\n",
    "# x = BatchNormalization()(x) \n",
    "# output_layer = Dense(output_shape[0], activation='linear')(x)\n",
    "\n",
    "# model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# # 모델 컴파일 및 훈련\n",
    "# model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "# model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "188/188 [==============================] - 6s 7ms/step - loss: 1.2466 - mse: 1.2466 - val_loss: 0.4459 - val_mse: 0.4459\n",
      "Epoch 2/100\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.6625 - mse: 0.6625 - val_loss: 0.4039 - val_mse: 0.4039\n",
      "Epoch 3/100\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.4833 - mse: 0.4833 - val_loss: 0.3589 - val_mse: 0.3589\n",
      "Epoch 4/100\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.4103 - mse: 0.4103 - val_loss: 0.3499 - val_mse: 0.3499\n",
      "Epoch 5/100\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.3865 - mse: 0.3865 - val_loss: 0.3425 - val_mse: 0.3425\n",
      "Epoch 6/100\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.3708 - mse: 0.3708 - val_loss: 0.3400 - val_mse: 0.3400\n",
      "Epoch 7/100\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.3656 - mse: 0.3656 - val_loss: 0.3371 - val_mse: 0.3371\n",
      "Epoch 8/100\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.3615 - mse: 0.3615 - val_loss: 0.3360 - val_mse: 0.3360\n",
      "Epoch 9/100\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.3588 - mse: 0.3588 - val_loss: 0.3362 - val_mse: 0.3362\n",
      "Epoch 10/100\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.3578 - mse: 0.3578 - val_loss: 0.3365 - val_mse: 0.3365\n",
      "Epoch 11/100\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.3565 - mse: 0.3565 - val_loss: 0.3362 - val_mse: 0.3362\n",
      "Epoch 12/100\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.3565 - mse: 0.3565 - val_loss: 0.3359 - val_mse: 0.3359\n",
      "Epoch 13/100\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.3560 - mse: 0.3560 - val_loss: 0.3360 - val_mse: 0.3360\n",
      "Epoch 14/100\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.3554 - mse: 0.3554 - val_loss: 0.3361 - val_mse: 0.3361\n",
      "Epoch 15/100\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.3551 - mse: 0.3551 - val_loss: 0.3365 - val_mse: 0.3365\n",
      "Epoch 16/100\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.3551 - mse: 0.3551 - val_loss: 0.3367 - val_mse: 0.3367\n",
      "Epoch 17/100\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.3550 - mse: 0.3550 - val_loss: 0.3362 - val_mse: 0.3362\n",
      "Epoch 18/100\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.3548 - mse: 0.3548 - val_loss: 0.3359 - val_mse: 0.3359\n",
      "Epoch 19/100\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.3546 - mse: 0.3546 - val_loss: 0.3361 - val_mse: 0.3361\n",
      "Epoch 20/100\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.3546 - mse: 0.3546 - val_loss: 0.3371 - val_mse: 0.3371\n",
      "Epoch 21/100\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.3543 - mse: 0.3543 - val_loss: 0.3363 - val_mse: 0.3363\n",
      "Epoch 22/100\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.3545 - mse: 0.3545 - val_loss: 0.3359 - val_mse: 0.3359\n",
      "Epoch 23/100\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.3545 - mse: 0.3545 - val_loss: 0.3358 - val_mse: 0.3358\n",
      "Epoch 24/100\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.3546 - mse: 0.3546 - val_loss: 0.3362 - val_mse: 0.3362\n",
      "Epoch 25/100\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.3544 - mse: 0.3544 - val_loss: 0.3362 - val_mse: 0.3362\n",
      "Epoch 26/100\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.3544 - mse: 0.3544 - val_loss: 0.3360 - val_mse: 0.3360\n",
      "Epoch 27/100\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.3544 - mse: 0.3544 - val_loss: 0.3366 - val_mse: 0.3366\n",
      "Epoch 28/100\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.3543 - mse: 0.3543 - val_loss: 0.3362 - val_mse: 0.3362\n",
      "Epoch 29/100\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.3543 - mse: 0.3543 - val_loss: 0.3359 - val_mse: 0.3359\n",
      "Epoch 30/100\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.3543 - mse: 0.3543 - val_loss: 0.3360 - val_mse: 0.3360\n",
      "Epoch 31/100\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.3543 - mse: 0.3543 - val_loss: 0.3361 - val_mse: 0.3361\n",
      "Epoch 32/100\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.3543 - mse: 0.3543 - val_loss: 0.3360 - val_mse: 0.3360\n",
      "Epoch 33/100\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.3543 - mse: 0.3543 - val_loss: 0.3362 - val_mse: 0.3362\n",
      "Epoch 34/100\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.3542 - mse: 0.3542 - val_loss: 0.3358 - val_mse: 0.3358\n",
      "Epoch 35/100\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.3543 - mse: 0.3543 - val_loss: 0.3363 - val_mse: 0.3363\n",
      "Epoch 36/100\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.3541 - mse: 0.3541 - val_loss: 0.3362 - val_mse: 0.3362\n",
      "Epoch 37/100\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.3542 - mse: 0.3542 - val_loss: 0.3359 - val_mse: 0.3359\n",
      "Epoch 38/100\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.3541 - mse: 0.3541 - val_loss: 0.3361 - val_mse: 0.3361\n",
      "Epoch 39/100\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.3542 - mse: 0.3542 - val_loss: 0.3360 - val_mse: 0.3360\n",
      "Epoch 40/100\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.3543 - mse: 0.3543 - val_loss: 0.3362 - val_mse: 0.3362\n",
      "Epoch 41/100\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.3541 - mse: 0.3541 - val_loss: 0.3361 - val_mse: 0.3361\n",
      "Epoch 42/100\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.3542 - mse: 0.3542 - val_loss: 0.3361 - val_mse: 0.3361\n",
      "Epoch 43/100\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.3541 - mse: 0.3541 - val_loss: 0.3364 - val_mse: 0.3364\n",
      "Epoch 44/100\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.3541 - mse: 0.3541 - val_loss: 0.3363 - val_mse: 0.3363\n",
      "Epoch 45/100\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.3540 - mse: 0.3540 - val_loss: 0.3361 - val_mse: 0.3361\n",
      "Epoch 46/100\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.3541 - mse: 0.3541 - val_loss: 0.3362 - val_mse: 0.3362\n",
      "Epoch 47/100\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.3540 - mse: 0.3540 - val_loss: 0.3359 - val_mse: 0.3359\n",
      "Epoch 48/100\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.3540 - mse: 0.3540 - val_loss: 0.3360 - val_mse: 0.3360\n",
      "Epoch 49/100\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.3542 - mse: 0.3542 - val_loss: 0.3365 - val_mse: 0.3365\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2ea89053f10>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
    "model.fit(X_train_sc, y_train, validation_split=0.2, batch_size=128, epochs=100, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235/235 [==============================] - 0s 915us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.31671899056149133"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(X_test_sc)\n",
    "pred = pd.DataFrame(pred)\n",
    "pred = pred.rename(columns={0:'사망자수', 1:'중상자수', 2:'경상자수', 3:'부상자수'})\n",
    "pred['ECLO'] = (pred['사망자수']*10) + (pred['중상자수']*5) + (pred['경상자수']*3) + (pred['부상자수']*1)\n",
    "calculate_rmsle(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7514, 5), (10963, 2))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape, sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "343/343 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(test_sc)\n",
    "pred = pd.DataFrame(pred)\n",
    "pred = pred.rename(columns={0:'사망자수', 1:'중상자수', 2:'경상자수', 3:'부상자수'})\n",
    "pred['ECLO'] = (pred['사망자수']*10) + (pred['중상자수']*5) + (pred['경상자수']*3) + (pred['부상자수']*1)\n",
    "\n",
    "sample.drop('ECLO', axis=1, inplace=True)\n",
    "sample['ECLO'] = pred['ECLO']\n",
    "sample.to_csv('submission8_DL4_.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
